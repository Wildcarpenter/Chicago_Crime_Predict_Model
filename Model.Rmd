---
title: 'Predictive Policing'
author: "Ziyi Guo"
date: "04/02/2024"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
---



```{r setup, include=FALSE}

knitr::opts_chunk$set(warning = FALSE)

library(tidyverse)
library(sf)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)   # for KDE and ML risk class intervals
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```


## Read in Data from Chicago

Read in data related to Chicago's potential risk predictors, such as 311 service requests concerning gun violence, sanitation reports, and abandoned vehicles, as well as information on current policing conditions including police districts, beats, and stations, along with past crime data.

```{r read_data, warning = FALSE, message = FALSE, results='hide'}

## Potential Predictors

#SHOTSPOTTER SINCE 2017
ShotSpotter <- 
  st_read("https://data.cityofchicago.org/resource/3h7q-7mdb.geojson") %>%
  st_transform('ESRI:102271')

#POLICE STATION 2016
Station_data <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Police_Stations.csv"))
PolStation <- 
  Station_data %>% 
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271')%>%
  dplyr::select(DISTRICT, ZIP)%>%
  mutate(Legend = "Pol_Station")

# Assuming Creation.Date is a character string or factor
abandonCars <- read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Abandoned_Vehicles.csv")) %>%
  dplyr::select(Latitude, Longitude, Creation.Date ) %>%
  filter(!is.na(Longitude) & !is.na(Latitude)) %>%
  filter(grepl("2017", `Creation.Date`)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271')%>%
  mutate(Legend = "AbandonedCars")


#SANITATION 2017
Sani_data <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Sanitation_Code_Complaints.csv"))
Sanitation <- 
  Sani_data %>% 
  dplyr::select(Latitude, Longitude, Creation.Date ) %>%
  filter(!is.na(Longitude) & !is.na(Latitude)) %>%
  filter(grepl("2017", `Creation.Date`)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271')%>%
  mutate(Legend = "Sanitation")

## Crime Data

#
# Read and process Robbery with Weapon data
Rob17 <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Crimes_-_2017.csv")) %>%
  filter(Primary.Type == "ROBBERY" & Description == "ARMED: HANDGUN") %>%  
  mutate(x = gsub("[()]", "", Location)) %>% 
  separate(x, into = c("Y", "X"), sep = ",") %>%  
  mutate(X = as.numeric(X), Y = as.numeric(Y)) %>%  
  na.omit() %>% 
  st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%  
  st_transform('ESRI:102271') %>%  
  distinct() 

# Read and process police districts data
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/fthy-xz3r?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%  
  dplyr::select(District = dist_num)  

# Read and process police beats data
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>% 
  dplyr::select(District = beat_num) 

## Boundary Data

# Read and process Chicago boundary data
chicagoBoundary <- 
  st_read(file.path(root.dir, "/Chapter5/chicagoBoundary.geojson")) %>%  
  st_transform('ESRI:102271') 

# Read neighborhood boundaries for Chicago and transform to match fishnet CRS
neighborhoods <- 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform('ESRI:102271')

```

## Visualizing crime point data


```{r, warning = FALSE, message = FALSE, results='hide'}
  
# Robberies overlaid on Chicago boundary
  ggplot() + 
    geom_sf(data = chicagoBoundary, fill = "lightgrey", colour = NA) +  
    geom_sf(data = Rob17, colour = "blue4", size = 0.1, show.legend = "point") +  
    labs(title = "Robberies, Chicago - 2017") +  # Set plot title
    theme_void()

```

*Selection Bias* 

Reporting Bias: Not all crimes are reported to the police. The likelihood of reporting can vary by type of crime, location, and demographic factors. For example, certain neighborhoods may have higher or lower rates of reporting due to trust in law enforcement, or the nature of the crime may be such that victims are reluctant to report it.

Recording Bias: Even when crimes are reported, there may be inconsistencies in how they are recorded. Different jurisdictions might classify crimes differently, and there might be human error in recording the details.

Law Enforcement Practices: Policing practices can influence where and how crimes are recorded. For example, areas with heavier police patrols may have higher recorded crime rates not because they are inherently more dangerous, but because there is a higher chance of crimes being observed and recorded.

Systemic Issues: Social, economic, and political factors can lead to certain groups being over-policed and over-represented in crime statistics. This can create a feedback loop where the perceived high crime rates in these communities lead to more intense policing, which in turn leads to more crime reports.

Technological Changes: Advancements in technology can change the way crimes are reported and recorded. For example, the introduction of online reporting systems might increase the reporting rate for certain types of crimes.

Media Influence: Media reporting on crime can influence public perception and reporting behavior. High-profile crimes might lead to increased reporting of similar crimes due to heightened awareness.


## Crime joined to fishnet grid

Generate a 500ft x 500ft fishnet grid and allocate the crime data to each cell within the grid.

```{r fishnet, warning = FALSE, message = FALSE, results='hide'}

# Create fishnet
fishnet <- 
st_make_grid(chicagoBoundary,
               cellsize = 500, # 500-coordinate system
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # fast way to select intersecting polygons
  st_sf() %>%   mutate(uniqueID = 1:n())


# Based on fishnet to aggregate crime
crime_net <- 
  dplyr::select(Rob17) %>% 
  mutate(countRob = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRob = replace_na(countRob, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = crime_net, aes(fill = countRob), color = NA) +
  scale_fill_viridis("Count of Robberies") +
  labs(title = "Count of Robberies for the fishnet") +
  theme_void()

```

The fishnet crime map helps in identifying hotspots of crime activity and can be an essential tool for urban planning and law enforcement to allocate resources more effectively. The distribution of the color intensities suggests a clustering of higher robbery counts in specific areas, which could warrant further investigation or targeted interventions


## Modeling Spatial Features

### Abandoned Cars

1. Abandoned Cars Count and knn

Quantify the number of abandoned vehicles within each grid cell and compute the distance from each cell to the five nearest abandoned vehicles.

```{r jointofishnet1, warning = FALSE, message = FALSE, results='hide'}

# COUNT
# Join the abandoned cars data with the fishnet grid based on spatial intersection
# a new spatial grid - abandoned cars

vars_net_Car <- abandonCars %>%  
  st_join(fishnet, join = st_within) %>%  
  st_drop_geometry() %>% 
  group_by(uniqueID, Legend) %>%  
  summarize(count = n()) %>% 
  left_join(fishnet, ., by = "uniqueID") %>%  
  spread(Legend, count, fill = 0) %>%  
  dplyr::select(-`<NA>`) %>%  #
  ungroup() 

# KNN
# Convenience aliases to reduce the length of function names
st_c    <- st_coordinates 
st_coid <- st_centroid    

# vars_net_Car include the count of the abandoned car and the 5 nn feature
vars_net_Car <- vars_net_Car %>%  
    mutate(Abandoned_Cars.nn = nn_function(  
        st_c(st_coid(vars_net_Car)),  # Calculate centroids of fishnet grid cells
        st_c(abandonCars),         # Get coordinates of abandoned cars
        k = 5                      # Number of nearest neighbors to find
    ))
# Visualize the nn
vars_net_Car.long.nn <- 
  dplyr::select(vars_net_Car, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

#join the abandoned cars (counts,k=5 nn) to the crime fishnet
final_net1 <-
  left_join(crime_net, st_drop_geometry(vars_net_Car), by="uniqueID") 


# LOCAL MORAN's I

## used to generate the weights of neighborhoods
## prerequisite for Local Moran

final_net1.nb <- poly2nb(as_Spatial(final_net1), queen=TRUE) # identify neighborhood units
final_net1.weights <- nb2listw(final_net1.nb, style="W", zero.policy=TRUE) #reflect the degree of spatial relationship or connection between them
print(final_net1.weights, zero.policy=TRUE)


# calculates the local Moran's I statistic for the Abandoned_Cars variable within the final_net data frame
local_morans <- localmoran(final_net1$Abandoned_Cars, final_net1.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net1.localMorans <- 
  cbind(local_morans, as.data.frame(final_net1)) %>% 
  st_sf() %>%
  dplyr::select(Abandoned_Cars_Count = AbandonedCars, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```


2.  Visualize local Moran's I results

Leverage Local Moran's I and associated P-values to ascertain the significance of hot spots, pinpointing areas with a high concentration of abandoned cars. The "Significant_Hotspots" map explicitly illuminates these areas, providing a clear visualization of where abandoned vehicles are most prevalent.

```{r fig.width=10, fig.height=4, warning = FALSE, message = FALSE, results='hide'}

vars <- unique(final_net1.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net1.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      theme_void() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Abandoned Cars"))
```

The hotspot areas, as indicated by the analysis, are predominantly situated in the southern region of the city.

3. Distance to Hot spot

```{r, warning = FALSE, message = FALSE, results='hide'}
# generates warning from NN

final_net1 <- final_net1 %>% 
  mutate(abandoned.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>% # identify hotspot area
  mutate(abandoned.isSig.dist = 
           nn_function(st_c(st_coid(final_net1)),
                       st_c(st_coid(filter(final_net1, 
                                           abandoned.isSig == 1))), # dist to the hotspot
                       k = 3))


ggplot() +
      geom_sf(data = final_net1, aes(fill=abandoned.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Abandoned Car NN Distance") +
      theme_void()
```

Consistent with the hotspot distribution, the northern part of the city exhibits longer distances to abandoned cars, while the southern areas, identified as hotspots, have relatively shorter distances to these vehicles.

### Sanitation

1. Sanitation Count and knn

Quantify the number of the sanitation reports within each grid cell and compute the distance from each cell to the five nearest sanitation reports.

```{r jointofishnet2, warning = FALSE, message = FALSE, results='hide'}

# Join the Sanitation Count data with the fishnet grid based on spatial intersection
# a new spatial grid - Sanitation Count

vars_net_Sani <- Sanitation %>%  
  st_join(fishnet, join = st_within) %>%  
  st_drop_geometry() %>% 
  group_by(uniqueID, Legend) %>%  
  summarize(count = n()) %>% 
  left_join(fishnet, ., by = "uniqueID") %>%  
  spread(Legend, count, fill = 0) %>%  
  dplyr::select(-`<NA>`) %>%  #
  ungroup() 

# KNN
# Convenience aliases to reduce the length of function names
st_c    <- st_coordinates 
st_coid <- st_centroid    


# vars_net_Sani include the count of the abandoned car and the 5 nn feature
centroids <- st_centroid(vars_net_Sani)

# Extract coordinates as matrices
centroids_coords <- st_coordinates(centroids)
sanitation_coords <- st_coordinates(st_geometry(Sanitation))

# Pass coordinates to the nn_function
vars_net_Sani <- vars_net_Sani %>%
  mutate(Sanitation.nn = nn_function(centroids_coords, sanitation_coords, k = 5))

# Visualize the nn
vars_net_Sani.long.nn <- 
  dplyr::select(vars_net_Sani, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)


#join the abandoned cars (counts,k=5 nn) to the initial
final_net2 <-
  left_join(final_net1, st_drop_geometry(vars_net_Sani), by="uniqueID") 


# LOCAL MORAN's I

## used to generate the weights of neighborhoods
## prerequisite for Local Moran

final_net2.nb <- poly2nb(as_Spatial(final_net2), queen=TRUE) # identify neighborhood units
final_net2.weights <- nb2listw(final_net2.nb, style="W", zero.policy=TRUE) 
print(final_net2.weights, zero.policy=TRUE)


# Local Moran
# calculates the local Moran's I statistic for the Sanitation variable within the final_net data frame
local_morans <- localmoran(final_net2$Sanitation, final_net2.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net2.localMorans <- 
  cbind(local_morans, as.data.frame(final_net2)) %>% 
  st_sf() %>%
  dplyr::select(SaniCount = Sanitation, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```


3.  Visualize local Moran's I results

*Identify Hot Spots Area*
using Local Moran's I, P value to identify the significance
Significant_Hotspots more directly shows the hot spots area, where abandoned cars concentrated.

```{r fig.width=10, fig.height=4, warning = FALSE, message = FALSE, results='hide'}

vars <- unique(final_net2.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net2.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      theme_void() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Sanitation Status"))
```

to identify the sanitation hotspot areas,

4. Distance to Hot spot

```{r, warning = FALSE, message = FALSE, results='hide'}
# generates warning from NN
final_net2 <- final_net2 %>% 
  mutate(Sani.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>% # identify hotspot area
  mutate(Sani.isSig.dist = 
           nn_function(st_c(st_coid(final_net2)),
                       st_c(st_coid(filter(final_net2, 
                                           Sani.isSig == 1))), # dist to the hotspot
                       k = 3))


ggplot() +
      geom_sf(data = final_net2, aes(fill=Sani.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Sanitation NN Distance") +
      theme_void()
```
### Police Station

1. police station Count and knn

```{r jointofishnet3, warning = FALSE, message = FALSE, results='hide'}

# Join the Sanitation Count data with the fishnet grid based on spatial intersection
# a new spatial grid - Sanitation Count


vars_net_station <- PolStation %>%  
  st_join(fishnet, join = st_within) %>%  
  st_drop_geometry() %>% 
  group_by(uniqueID, Legend) %>%  
  summarize(count = n()) %>% 
  left_join(fishnet, ., by = "uniqueID") %>%  
  spread(Legend, count, fill = 0) %>%  
  dplyr::select(-`<NA>`) %>%  #
  ungroup() 

# KNN
# Convenience aliases to reduce the length of function names
st_c    <- st_coordinates 
st_coid <- st_centroid    


# vars_net_station include the count of the abandoned car and the 5 nn feature
centroids <- st_centroid(vars_net_station)

# Extract coordinates as matrices
centroids_coords <- st_coordinates(centroids)
station_coords <- st_coordinates(st_geometry(PolStation))

# Pass coordinates to the nn_function
vars_net_station <- vars_net_station %>%
  mutate(PolStation.nn = nn_function(centroids_coords, station_coords, k = 5))

# Visualize the nn
vars_net_station.long.nn <- 
  dplyr::select(vars_net_station, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)


#join the abandoned cars (counts,k=5 nn) to the initial
final_net3 <-
  left_join(final_net2, st_drop_geometry(vars_net_station), by="uniqueID") 

```


2. Local Moran's I

```{r, warning = FALSE, message = FALSE, results='hide'}

## used to generate the weights of neighborhoods
## prerequisite for Local Moran
final_net3.nb <- poly2nb(as_Spatial(final_net3), queen=TRUE) # identify neighborhood units
final_net3.weights <- nb2listw(final_net3.nb, style="W", zero.policy=TRUE) 
print(final_net3.weights, zero.policy=TRUE)


# Local Moran
# calculates the local Moran's I statistic for the Police Stations variable within the final_net data frame
local_morans <- localmoran(final_net3$PolStat, final_net3.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net3.localMorans <- 
  cbind(local_morans, as.data.frame(final_net3)) %>% 
  st_sf() %>%
  dplyr::select(polCount = Pol_Station, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```


3.  Visualize local Moran's I results

*Identify Hot Spots Area*
using Local Moran's I, P value to identify the significance
Significant_Hotspots more directly shows the hot spots area, where abandoned cars concentrated.

```{r fig.width=10, fig.height=4, warning = FALSE, message = FALSE, results='hide'}

vars <- unique(final_net3.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net3.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      theme_void() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Police Station"))
```


4. Distance to Hot spot

```{r, warning = FALSE, message = FALSE, results='hide'}
# generates warning from NN
final_net3 <- final_net3 %>% 
  mutate(Station.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>% # identify hotspot area
  mutate(Station.isSig.dist = 
           nn_function(st_c(st_coid(final_net3)),
                       st_c(st_coid(filter(final_net3, 
                                           Station.isSig == 1))), # dist to the hotspot
                       k = 3))


ggplot() +
      geom_sf(data = final_net3, aes(fill=Station.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Police Station NN Distance") +
      theme_void()
```

### Combine with neighborhoods and policing districts

```{r, warning = FALSE, message = FALSE, results='hide'}
final_net3 <-
  st_centroid(final_net3) %>%
    st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
    st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net3, geometry, uniqueID)) %>%
      st_sf() %>%
  na.omit()
```

### Variables Correlation

```{r, warning = FALSE, message = FALSE, results='hide'}

final_net3_long <- pivot_longer(
  data = final_net3,
  cols = c("Abandoned_Cars.nn", "abandoned.isSig.dist", "Sanitation.nn", "Sani.isSig.dist", "PolStation.nn", "Station.isSig.dist"),
  names_to = "Variable",
  values_to = "Value"
)

# Create the plot
ggplot(final_net3_long, aes(x = Value, y = countRob)) +
  geom_point(size = 0.3) +
  geom_smooth(method = "lm", se = FALSE, color = "skyblue2") +
  facet_wrap(~Variable, ncol = 3, scales = "free") +
  labs(title = "Correlation with countRob") +
  theme_minimal()

```

abandoned.isSig.dist: This scatter plot compares the count of robberies (countRob) with the distance to significant clusters of abandoned cars. The trend line suggests that as the distance to significant clusters of abandoned cars increases, the count of robberies tends to decrease, albeit with a wide spread of data points that indicate variability in the correlation.

Abandoned_Cars.nn: This scatter plot shows the relationship between the count of robberies and the nearest neighbor count of abandoned cars. The trend seems to suggest a slight decrease in robberies as the number of nearby abandoned cars increases, but again with a wide distribution of points.

Sani.isSig.dist: The count of robberies is plotted against the distance to significant clusters of sanitation reports. The trend line indicates a negative relationship, where robbery counts decrease as the distance to sanitation issues increases, which might suggest that areas with more sanitation reports also see more robberies.

Sanitation.nn: This plot shows the count of robberies against the nearest neighbor count of sanitation reports. The downward trend line suggests that higher sanitation report counts may be associated with lower robbery counts, but the dispersion of the data points is quite broad.

PolStation.nn: This shows the relationship between the count of robberies and the count of nearest neighbors to police stations. The trend line is downward, indicating that as the proximity to police stations increases (i.e., more police stations in the vicinity), the count of robberies tends to decrease.

Station.isSig.dist: Finally, this scatter plot correlates the count of robberies with the distance to significant police station locations. The trend line indicates a slight decrease in the count of robberies as the distance to police stations increases, which may imply that closer proximity to police stations is associated with fewer robberies.

### Histogram of dependent variables (Robbery count)

```{r, warning = FALSE, message = FALSE, results='hide'}
ggplot(final_net3, aes(x = countRob)) + 
  geom_histogram(binwidth = 1, fill = "skyblue4", color = "white") +
  labs(title = "Histogram of countRob",
       x = "countRob",
       y = "Frequency") +
  theme_minimal()
```
From the chart, it's clear that the majority of data points have a low count of robberies, with the first bin being the most populated, indicating a high frequency of areas with few or no reported robberies. As the count of robberies increases, the frequency drastically decreases, showing that higher robbery counts are less common. The concentration of data in the lower count range could suggest that while robberies do occur across the grid, they are generally less frequent and there are fewer areas with high robbery rates. 


## Modeling and CV

Construct a regression model incorporating the identified variables.

```{r, warning = FALSE, message = FALSE, results='hide'}

## define the variables we want
reg.vars <- c("Abandoned_Cars.nn", "Sanitation.nn", "PolStation.nn")

reg.ss.vars <- c("Abandoned_Cars.nn", "abandoned.isSig.dist", "Sanitation.nn", "Sani.isSig.dist", "PolStation.nn", "Station.isSig.dist")

reg.cv <- crossValidate(
  dataset = final_net3,
  id = "cvID",
  dependentVariable = "countRob",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countRob, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net3,
  id = "cvID",
  dependentVariable = "countRob",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countRob, Prediction, geometry)
  
reg.spatialCV <- crossValidate(
  dataset = final_net3,
  id = "name",
  dependentVariable = "countRob",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = name, countRob, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net3,
  id = "name",
  dependentVariable = "countRob",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countRob, Prediction, geometry)

```


### Cross Validation & K Fold MAE Comparison

```{r fig.width=10, fig.height=4, warning = FALSE, message = FALSE, results='hide'}


reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countRob,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countRob,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countRob,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countRob,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf()
  
error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countRob, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="white", fill = "lightskyblue4") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count") +
    plotTheme()
```

Models validated with Spatial LOGO-CV exhibit more variability in MAE compared to those validated with random k-fold CV, which is expected as LOGO-CV accounts for spatial autocorrelation by leaving out clustered observations.

The 'Spatial Process' model generally shows a more concentrated MAE distribution, suggesting that including spatial relationships improves the consistency of the model’s predictive accuracy.

The comparison between cross-validation methods for each type of model indicates that the way in which data is partitioned for validation (randomly or spatially) can significantly affect the evaluation of model performance, with spatial methods likely offering a more realistic assessment for spatial data.

```{r, warning = FALSE, message = FALSE}
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable() %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "lightgrey") %>%
    row_spec(4, color = "black", background = "lightgrey") 
```

Random k-fold CV: Just Risk Factors: The model using only risk factors has a mean MAE of 0.39 and a standard deviation of 0.30. This suggests moderate predictive error with some variability across the k-folds.

Random k-fold CV: Spatial Process: The spatial process model under random k-fold CV has a similar mean MAE of 0.38 but a slightly higher standard deviation of 0.31. This indicates a comparable predictive performance to the risk factors model with a little more inconsistency between folds.

Spatial LOGO-CV: Just Risk Factors: When spatial considerations are factored into CV, the mean MAE for the risk factors model jumps to 0.95 with a high standard deviation of 0.83. This indicates less predictive accuracy and more variability when the spatial structure of the data is accounted for.

Spatial LOGO-CV: Spatial Process: The spatial process model with spatial LOGO-CV has a mean MAE of 0.92 and a standard deviation of 0.81, which is slightly better than the risk factors model in mean error but with a similarly high level of variability.

From these results, it can be inferred that when spatial autocorrelation is considered during model validation (Spatial LOGO-CV), the predictive error increases compared to random cross-validation. This suggests that the spatial structure of the data is significant and that models that do not account for this may be overestimating their predictive performance. It also demonstrates that spatial process models are slightly more robust to spatial validation methods than models considering only risk factors, as indicated by the marginally lower mean MAE. The high standard deviations in the spatial CV models indicate a large variability in the errors, reflecting the complex nature of spatial data that might not be captured entirely by the model.

### Racial Context

A table of raw errors by race context for a random k-fold vs. spatial cross validation regression.

```{r Racial, warning = FALSE, message = FALSE, results='hide'}

tracts18 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E"), 
          year = 2018, state=17, county=031, geometry=T) %>%
  st_transform('ESRI:102271')  %>% 
  dplyr::select(variable, estimate, GEOID) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B01001_001,
         NumberWhites = B01001A_001) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority_White", "Majority_Non_White")) %>%
  .[neighborhoods,]
```

```{r Racial2, warning = FALSE, message = FALSE}
reg.summary %>% 
  filter(str_detect(Regression, "LOGO")) %>%
    st_centroid() %>%
    st_join(tracts18) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = mean(Error, na.rm = T)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Mean Error by neighborhood racial context") %>%
        kable_styling("striped", full_width = F)  

```

Spatial LOGO-CV: Just Risk Factors:
Majority_Non_White' has a negative coefficient of approximately -0.6318, suggesting that an increase in the non-white majority population is associated with a decrease in the response variable, which could be the count of incidents or a similar metric, in this model.
'Majority_White' has a positive coefficient of approximately 0.6869, indicating that an increase in the white majority population is associated with an increase in the response variable.

Spatial LOGO-CV: Spatial Process:
'Majority_Non_White' has a negative coefficient of approximately -0.5967, which is still negative but slightly less so compared to the Just Risk Factors model.
'Majority_White' has a positive coefficient of approximately 0.6433, which is positive and also slightly lower than in the Just Risk Factors model.

These coefficients suggest that there is a racial demographic relationship to the response variable being modeled, with non-white majority areas negatively associated and white majority areas positively associated with the outcome. However, these relationships are less pronounced in the Spatial Process model compared to the Just Risk Factors model. This could imply that including spatial processes in the model partially mitigates the apparent influence of these demographic factors.

### Distribution of MAE and MAE by Neighborhood

```{r, warning = FALSE, message = FALSE, results='hide'}
# calculate errors by NEIGHBORHOOD
error_by_reg_and_fold <- 
  reg.ss.spatialCV %>%
    group_by(cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countRob, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>% 
  arrange(MAE)

## plot histogram of OOF (out of fold) errors
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="white", fill = "lightskyblue4") +
  scale_x_continuous(breaks = seq(0, 11, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count") 
```

The majority of MAE values are between 0 and 1, indicating that for most of the validation groups, the average error between the predicted and actual values is less than 1 unit. This could be considered a good predictive performance, depending on the specific context and scale of the response variable.

The frequency of MAE values decreases as the error increases. There are fewer instances where the model's predictions were off by more than 1 unit.

The histogram shows a right-skewed distribution, with most of the data clustered on the lower end of MAE values and the tail stretching towards the higher MAE values.

There is a long tail of higher MAE values, although these occur less frequently. This suggests there may be outliers or specific instances where the model performs poorly.


### Comparison with 2018 Robbery Data


```{r, warning = FALSE, message = FALSE, results='hide'}
Rob18 <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Crimes_-_2018.csv")) %>% 
  filter(Primary.Type == "ROBBERY" & Description == "ARMED: HANDGUN") %>%
  mutate(x = gsub("[()]", "", Location)) %>%
  separate(x,into= c("Y","X"), sep=",") %>%
  mutate(X = as.numeric(X),
         Y = as.numeric(Y)) %>% 
  na.omit %>%
  st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271') %>% 
  distinct() %>%
  .[fishnet,]

burg_ppp <- as.ppp(st_coordinates(Rob17), W = st_bbox(final_net3))
burg_KD.1000 <- density.ppp(burg_ppp, 1000)

burg_KDE_sum <- as.data.frame(burg_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net3)) %>%
  aggregate(., final_net3, mean) 
kde_breaks <- classIntervals(burg_KDE_sum$value, 
                             n = 5, "fisher")

##put into discrete groups
burg_KDE_sf <- burg_KDE_sum %>%
  mutate(label = "Kernel Density",
         Risk_Category = classInt::findCols(kde_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(Rob18) %>% mutate(robCount = 1), ., sum) %>%
    mutate(robCount = replace_na(robCount, 0))) %>%
  dplyr::select(label, Risk_Category, robCount)

ml_breaks <- classIntervals(reg.ss.spatialCV$Prediction, 
                             n = 5, "fisher")
burg_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(Rob18) %>% mutate(robCount = 1), ., sum) %>%
      mutate(robCount = replace_na(robCount, 0))) %>%
  dplyr::select(label,Risk_Category, robCount)

rbind(burg_KDE_sf, burg_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(Rob18, 3000), size = .1, colour = "white") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2017 Robberies risk predictions; 2018 Robberies") +
    mapTheme(title_size = 14)
```


1st Risk Category: There's a notable discrepancy in the first risk category, with the prediction model significantly underestimating the percentage of robberies that fall into the highest risk category. The spatial map confirms that the model failed to capture the concentration of the highest risk areas.

2nd and 3rd Risk Categories: For the second and third risk categories, the prediction model seems to overestimate the percentage of robberies when compared to the kernel density. This suggests that the model may misclassify some areas into a higher risk category than they actually are. The spatial distribution might show a broader spread of moderate risk than what actually occurred.

4th Risk Category: The predicted and actual data are closely aligned in the fourth risk category, indicating the model's accuracy for lower-middle-risk areas.

5th Risk Category: There's an underestimation in the prediction for the lowest risk category. This underestimation, combined with the overestimation in the second and third categories, may imply that the model is biased towards predicting a higher risk than exists.

```{r, warning = FALSE, message = FALSE, results='hide'}
rbind(burg_KDE_sf, burg_risk_sf) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countRob = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Pcnt_of_test_set_crimes = countRob / sum(countRob)) %>%
    ggplot(aes(Risk_Category,Pcnt_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_manual(values=c("khaki", "lightskyblue3")) +
      labs(title = "Risk prediction vs. Kernel density, 2018 Robberies",
           y = "% of Test Set Robberies (per model)",
           x = "Risk Category") +
  theme_bw() +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```


The model is conservative in predicting the highest risk areas, which might cause insufficient resource allocation to the most vulnerable spots.There is an over-prediction in the mid-risk categories, which could lead to an over-allocation of resources to areas that do not require as intensive monitoring or intervention.The accuracy in the fourth category suggests that the model has some predictive power and is not uniformly over or underestimating across all categories. The under-prediction in the lowest risk category might not be as critical from a resource allocation perspective, but it still indicates that the model’s threshold for risk is skewed.

The predictive model’s underestimation of the highest risk robbery areas and overestimation of mid-level risks, as shown in the comparison between prediction and kernel density, suggests it's not yet suited for deployment. The spatial maps underscore the urgency for recalibration to accurately target resources, avoid potential biases, and ensure public safety without misdirecting law enforcement efforts. Before considering production use, the model demands rigorous refinement, transparent methodology, and ethical oversight, coupled with an ongoing validation process that adapts to evolving crime patterns and incorporates a broader spectrum of data for enhanced accuracy.
