---
title: 'Predictive Policing'
author: "Ziyi Guo"
date: "04/02/2024"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

install.packages(RSocrata)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)   # for KDE and ML risk class intervals
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

## Read in Data from Chicago


```{r read_data}

## Potential Predictors

#SHOTSPOTTER SINCE 2017
ShotSpotter <- 
  st_read("https://data.cityofchicago.org/resource/3h7q-7mdb.geojson") %>%
  st_transform('ESRI:102271')

#POLICE STATION 2016
Station_data <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Police_Stations.csv"))
PolStation <- 
  Station_data %>% 
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271')%>%
  dplyr::select(DISTRICT, ZIP)

# ABANDONED VEHICLES 2017
abandonCars <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Abandoned-Vehicles/3c9v-pnva") %>%
    # Extract the year from the creation date and filter for the year 2017
    mutate(year = substr(creation_date, 1, 4)) %>% filter(year == "2017") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform('ESRI:102271') %>%
    mutate(Legend = "Abandoned_Cars")

#SANITATION 2017
Sani_data <- 
  read.csv(file.path("C:/Users/25077/Desktop/MUSA 508_PPA/Chicago_Crime_Predict_Model/Chicago_Crime_Predict_Model/Sanitation_Code_Complaints.csv"))
Sanitation <- 
  Sani_data %>% 
  filter(!is.na(Longitude) & !is.na(Latitude)) %>%
  filter(grepl("2017", `Creation.Date`)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271')%>%
  dplyr::select(Creation.Date, Police.District, ZIP.Code)

## Crime Data

# Read and process Robbery with Weapon data
Rob17 <- 
  read.socrata("https://data.cityofchicago.org/Public-Safety/Crimes-2017/d62x-nvdr") %>% 
  filter(Primary.Type == "ROBBERY" & Description == "ARMED: HANDGUN") %>%  
  mutate(x = gsub("[()]", "", Location)) %>% 
  separate(x, into = c("Y", "X"), sep = ",") %>%  
  mutate(X = as.numeric(X), Y = as.numeric(Y)) %>%  
  na.omit() %>% 
  st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%  
  st_transform('ESRI:102271') %>%  
  distinct() 

# Read and process police districts data
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/fthy-xz3r?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%  
  dplyr::select(District = dist_num)  

# Read and process police beats data
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>% 
  dplyr::select(District = beat_num) 

## Boundary Data

# Read and process Chicago boundary data
chicagoBoundary <- 
  st_read(file.path(root.dir, "/Chapter5/chicagoBoundary.geojson")) %>%  
  st_transform('ESRI:102271') 

# Read neighborhood boundaries for Chicago and transform to match fishnet CRS
neighborhoods <- 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform(st_crs(fishnet))

```

## visualizing point data

Plotting point data and density


```{r fig.width=6, fig.height=4}
# Uses grid.arrange to organize independent plots

grid.arrange(
  ncol = 2,
  
  # Plot 1: Robberies overlaid on Chicago boundary
  ggplot() + 
    geom_sf(data = chicagoBoundary) +  
    geom_sf(data = Rob17, colour = "indianred", size = 0.1, show.legend = "point") +  # Overlay burglaries
    labs(title = "Robberies, Chicago - 2017") +  # Set plot title
    theme_void(),
  
  # Plot 2: Density of burglaries with contours overlaid on Chicago boundary
  ggplot() + 
    geom_sf(data = chicagoBoundary, fill = "grey40") +  # Add Chicago boundary with grey fill
    stat_density2d(data = data.frame(st_coordinates(Rob17)),  # Compute 2D kernel density estimate
                   aes(X, Y, fill = ..level.., alpha = ..level..),  # Define aesthetics for density contours
                   size = 0.01, bins = 40, geom = 'polygon') +  # Set size and number of bins for contours
    scale_fill_viridis() +  # Use Viridis color scale for fill
    scale_alpha(range = c(0.00, 0.35), guide = FALSE) +  # Set transparency range for contours
    labs(title = "Density of Robberies") + 
    theme_void() + theme(legend.position = "none")
)

```

## Creating a fishnet grid

> What is a fishnet grid?

The `{sf}` package offers really easy way to create fishnet grids using the `st_make_grid()` function. The `cellsize` argument allows you to set the size of the grid cells; in this case it is set to `500` meters. You may have to do some research on the spatial layers projection (using `st_crs()` to know what coordinate system you are in) to understand if you are in feet or meters. If you are using Longitude and Latitude, you will need to project the data to a projected coordinate system to get distance measurements.

Examine the fishnet - the unique ID is crucial to building a data set!

```{r fishnet}
## using {sf} to create the grid
## Note the `.[chicagoBoundary] %>% ` line. This is needed to clip the grid to our data
fishnet <- 
st_make_grid(chicagoBoundary,
               cellsize = 500, # 500-coordinate system
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # fast way to select intersecting polygons
  st_sf() %>%   mutate(uniqueID = 1:n())




```

### Aggregate points to the fishnet

> How can we aggregate points into a fishnet grid?

```{r spatialjoin}
## add a value of 1 to each crime, sum them with aggregate
crime_net <- 
  dplyr::select(Rob17) %>% 
  mutate(countRob = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRob = replace_na(countRob, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = crime_net, aes(fill = countRob), color = NA) +
  scale_fill_viridis("Count of Robberies") +
  labs(title = "Count of Robberies for the fishnet") +
  theme_void()

```

kernel density


## Modeling Spatial Features

#### How we aggregate a feature to our fishnet


```{r jointofishnet}

# Join the abandoned cars data with the fishnet grid based on spatial intersection
vars_net_Car <- abandonCars %>%  
  st_join(fishnet, join = st_within) %>%  
  st_drop_geometry() %>% 
  group_by(uniqueID, Legend) %>%  
  summarize(count = n()) %>% 
  left_join(fishnet, ., by = "uniqueID") %>%  
  spread(Legend, count, fill = 0) %>%  
  dplyr::select(-`<NA>`) %>%  #
  ungroup() 

# KNN
# Convenience aliases to reduce the length of function names
st_c    <- st_coordinates  # Alias for st_coordinates function
st_coid <- st_centroid     # Alias for st_centroid function


vars_net5 <- vars_net_Car %>%  # Start with the summarized variables data
    mutate(Abandoned_Cars.nn = nn_function(  # Create a new column for nearest neighbor information
        st_c(st_coid(vars_net_Car)),  # Calculate centroids of fishnet grid cells
        st_c(abandonCars),         # Get coordinates of abandoned cars
        k = 5                      # Number of nearest neighbors to find
    ))

# Visualize the nn
vars_net5.long.nn <- 
  dplyr::select(vars_net5, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net5.long.nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN5 Distance") +
      labs(title="Abandoned Car NN5 Distance") +
      theme_void()
```




## Join NN feature to our fishnet

Since the counts were aggregated to each cell by `uniqueID` we can use that to join the counts to the fishnet.

```{r}
## important to drop the geometry from joining features
final_net <-
  left_join(crime_net, st_drop_geometry(vars_net_Car), by="uniqueID") 

```

### Join in areal data

Using spatial joins to join *centroids* of fishnets to polygon for neighborhoods and districts.


```{r}

final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
    st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() %>%
  na.omit()

```

## Local Moran's I for fishnet grid cells



```{r}

## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

print(final_net.weights, zero.policy=TRUE)


# Local Moran
local_morans <- localmoran(final_net$Abandoned_Cars, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Abandoned_Cars_Count = Abandoned_Cars, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```


### Visualize local Moran's I results

*Identify Hot Spots Area*
using Local Moran's I, P value to identify the significance
Significant_Hotspots more directly shows the hot spots area, where abandoned cars concentrated.

```{r fig.width=10, fig.height=4}

vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      theme_void() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Abandoned Cars"))
```


## Distance to Hot spot

Using NN distance to a hot spot location

```{r}
# generates warning from NN
final_net <- final_net %>% 
  mutate(abandoned.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>% # identify hotspot area
  mutate(abandoned.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           abandoned.isSig == 1))), # dist to the hotspot
                       k = 3))


ggplot() +
      geom_sf(data = final_net, aes(fill=abandoned.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Abandoned Car NN Distance") +
      theme_void()
```

## Modeling and CV

Leave One Group Out CV on spatial features

```{r results='hide'}

View(crossValidate)

## define the variables we want
reg.ss.vars <- c("Abandoned_Cars.nn", "abandoned.isSig.dist")

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",                           
  dependentVariable = "countBurglaries",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countBurglaries, Prediction, geometry)

summary(reg.ss.spatialCV)
```

```{r}
# calculate errors by NEIGHBORHOOD
error_by_reg_and_fold <- 
  reg.ss.spatialCV %>%
    group_by(cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countBurglaries, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>% 
  arrange(desc(MAE))
error_by_reg_and_fold %>% 
  arrange(MAE)

## plot histogram of OOF (out of fold) errors
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
  scale_x_continuous(breaks = seq(0, 11, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count") 
```

negative 
under-predicting

## Density vs predictions

The `spatstat` function gets us kernal density estimates with varying search radii.

Note that the code here is *different* than in the book - it has been updated to keep up with changes in packages.

```{r}
# demo of kernel width
burg_ppp <- as.ppp(st_coordinates(burglaries), W = st_bbox(final_net))
burg_KD.1000 <- density.ppp(burg_ppp, 1000)
burg_KD.1500 <- density.ppp(burg_ppp, 1500)
burg_KD.2000 <- density.ppp(burg_ppp, 2000)
burg_KD.df <- rbind(
  mutate(data.frame(rasterToPoints(mask(raster(burg_KD.1000), as(neighborhoods, 'Spatial')))), Legend = "1000 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(burg_KD.1500), as(neighborhoods, 'Spatial')))), Legend = "1500 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(burg_KD.2000), as(neighborhoods, 'Spatial')))), Legend = "2000 Ft.")) 

burg_KD.df$Legend <- factor(burg_KD.df$Legend, levels = c("1000 Ft.", "1500 Ft.", "2000 Ft."))

ggplot(data=burg_KD.df, aes(x=x, y=y)) +
  geom_raster(aes(fill=layer)) + 
  facet_wrap(~Legend) +
  coord_sf(crs=st_crs(final_net)) + 
  scale_fill_viridis(name="Density") +
  labs(title = "Kernel density with 3 different search radii") +
  mapTheme(title_size = 14)
```

```{r}

as.data.frame(burg_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(burglaries, 1500), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of 2017 burglaries") +
     mapTheme(title_size = 14)
```

## Get 2018 crime data

Let's see how our model performed relative to KD on the following year's data.

```{r}
burglaries18 <- 
  read.socrata("https://data.cityofchicago.org/Public-Safety/Crimes-2018/3i3m-jwuy") %>% 
  filter(Primary.Type == "BURGLARY" & 
         Description == "FORCIBLE ENTRY") %>%
  mutate(x = gsub("[()]", "", Location)) %>%
  separate(x,into= c("Y","X"), sep=",") %>%
  mutate(X = as.numeric(X),
         Y = as.numeric(Y)) %>% 
  na.omit %>%
  st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271') %>% 
  distinct() %>%
  .[fishnet,]
```

```{r}

burg_KDE_sum <- as.data.frame(burg_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) 
kde_breaks <- classIntervals(burg_KDE_sum$value, 
                             n = 5, "fisher")

##put into discrete groups
burg_KDE_sf <- burg_KDE_sum %>%
  mutate(label = "Kernel Density",
         Risk_Category = classInt::findCols(kde_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(burglaries18) %>% mutate(burgCount = 1), ., sum) %>%
    mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label, Risk_Category, burgCount)
```

Note that this is different from the book, where we pull a model out of a list of models we've created. For your homework, you'll be creating multiple models.

```{r}
ml_breaks <- classIntervals(reg.ss.spatialCV$Prediction, 
                             n = 5, "fisher")
burg_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(burglaries18) %>% mutate(burgCount = 1), ., sum) %>%
      mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label,Risk_Category, burgCount)
```

We don't do quite as well because we don't have very many features, but still pretty good.

```{r}
rbind(burg_KDE_sf, burg_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(burglaries18, 3000), size = .2, colour = "red2") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2017 burglar risk predictions; 2018 burglaries") +
    mapTheme(title_size = 14)
```
whether result matches with the real-situation.

```{r}
rbind(burg_KDE_sf, burg_risk_sf) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countBurglaries = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Pcnt_of_test_set_crimes = countBurglaries / sum(countBurglaries)) %>%
    ggplot(aes(Risk_Category,Pcnt_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE, name = "Model") +
      labs(title = "Risk prediction vs. Kernel density, 2018 burglaries",
           y = "% of Test Set Burglaries (per model)",
           x = "Risk Category") +
  theme_bw() +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```
